{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of this prototype is to fetch the lyrics of a specific song, in preparation for the full script that will iterate through the yearly data.\n",
    "\n",
    "songdata = pd.read_csv('data/2019top10songs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<!DOCTYPE html>\n<html lang=\"en\">\n <head>\n  <meta charset=\"utf-8\"/>\n  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n  <meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/>\n  <meta content=\"Panic! At The Disco &quot;High Hopes&quot;: (High, high hopes) Had to have high, high hopes for a living Shooting for the stars when I couldn't...\" name=\"description\"/>\n  <meta content=\"High Hopes lyrics, Panic! At The Disco High Hopes lyrics, Panic! At The Disco lyrics\" name=\"keywords\"/>\n  <meta content=\"noarchive\" name=\"robots\"/>\n  <meta content=\"//www.azlyrics.com/az_logo_tr.png\" property=\"og:image\"/>\n  <title>\n   Panic! At The Disco - High Hopes Lyrics | AZLyrics.com\n  </title>\n  <link href=\"https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css\" rel=\"stylesheet\"/>\n  <link href=\"//www.azlyrics.com/bsaz.css?4\" rel=\"stylesheet\"/>\n  <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->\n  <!--[if lt IE 9]>\n<script src=\"https://o\n"
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.3'}\n",
    "cookies = { 'sessionid': '123..'}\n",
    "i = 5 # Set i to the position in the songdata datafrae you would like to examine.\n",
    "url = 'https://www.azlyrics.com/lyrics/'\n",
    "artist = songdata['Artist'][i] # artist1 and artist2 are the most common ways azlyrics represents artist names. artist1 removes spaces while artist2 replaces                                  them with a dash. artist3 and artist4 handle the way that Wikipedia presents collaborations.\n",
    "artist1 = ''.join(artist.split()).lower().replace('\\'','').replace(',','').replace('!','')\n",
    "artist2 = artist.lower().replace('\\'','').replace(',','').replace(' ','-').replace('!','')\n",
    "artist3 = artist1[:artist1.rfind('and')]\n",
    "artist4 = artist2[:artist2.rfind('-and')]\n",
    "title = ''.join(songdata['Title'][i].split()).lower() # azlyrics seems to represent all song titles in the same way.\n",
    "if requests.get(url + artist1 + '/' + title + '.html').status_code == 200:\n",
    "    html = requests.get(url + artist1 + '/' + title + '.html',cookies=cookies,headers=headers).text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    print(soup.prettify()[0:1000])\n",
    "elif requests.get(url + artist2 + '/' + title + '.html').status_code == 200:\n",
    "    html = requests.get(url + artist2 + '/' + title + '.html').text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    print(soup.prettify()[0:1000])\n",
    "elif requests.get(url + artist3 + '/' + title + '.html').status_code == 200:\n",
    "    html = requests.get(url + artist3 + '/' + title + '.html').text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    print(soup.prettify()[0:1000])\n",
    "elif requests.get(url + artist4 + '/' + title + '.html').status_code == 200:\n",
    "    html = requests.get(url + artist4 + '/' + title + '.html').text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    print(soup.prettify()[0:1000])\n",
    "else:\n",
    "    print('Song at position ' + str(i) + ' not found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'panic!atthedisco'"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = soup.find('div',attrs={'class': None}).text.replace('\\n',' ')[3:] # Extract lyrics text from the azlyrics page and replace newlines with spaces. Also, eliminate the \\r tag and space at the beginning.\n",
    "try:\n",
    "    my_text = my_text[:my_text.rindex(\"[\")-1] # Remove miscellaneous notes at the end of lyrics.\n",
    "except ValueError:\n",
    "    my_text = my_text\n",
    "my_text = word_tokenize(my_text)\n",
    "my_text = [i.lower() for i in my_text if not re.fullmatch('[' + string.punctuation + ']+', i)] #Remove tokens that are just punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'shooting', 'for', 'the', 'star', 'when', 'i', 'could', \"n't\", 'make', 'a', 'killing', 'did', \"n't\", 'have', 'a', 'dime', 'but', 'i', 'always', 'had', 'a', 'vision', 'always', 'had', 'high', 'high', 'hope', 'high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'did', \"n't\", 'know', 'how', 'but', 'i', 'always', 'had', 'a', 'feeling', 'i', 'wa', 'gon', 'na', 'be', 'that', 'one', 'in', 'a', 'million', 'always', 'had', 'high', 'high', 'hope', 'mama', 'said', 'fulfill', 'the', 'prophecy', 'be', 'something', 'greater', 'go', 'make', 'a', 'legacy', 'manifest', 'destiny', 'back', 'in', 'the', 'day', 'we', 'wanted', 'everything', 'wanted', 'everything', 'mama', 'said', 'burn', 'your', 'biography', 'rewrite', 'your', 'history', 'light', 'up', 'your', 'wildest', 'dream', 'museum', 'victory', 'every', 'day', 'we', 'wanted', 'everything', 'wanted', 'everything', 'mama', 'said', 'do', \"n't\", 'give', 'up', 'it', \"'s\", 'a', 'little', 'complicated', 'all', 'tied', 'up', 'no', 'more', 'love', 'and', 'i', \"'d\", 'hate', 'to', 'see', 'you', 'waiting', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'shooting', 'for', 'the', 'star', 'when', 'i', 'could', \"n't\", 'make', 'a', 'killing', 'did', \"n't\", 'have', 'a', 'dime', 'but', 'i', 'always', 'had', 'a', 'vision', 'always', 'had', 'high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'did', \"n't\", 'know', 'how', 'but', 'i', 'always', 'had', 'a', 'feeling', 'i', 'wa', 'gon', 'na', 'be', 'that', 'one', 'in', 'a', 'million', 'always', 'had', 'high', 'high', 'hope', 'high', 'high', 'hope', 'mama', 'said', 'it', \"'s\", 'uphill', 'for', 'oddity', 'stranger', 'crusader', 'ai', \"n't\", 'ever', 'wannabe', 'the', 'weird', 'and', 'the', 'novelty', 'do', \"n't\", 'ever', 'change', 'we', 'wanted', 'everything', 'wanted', 'everything', 'high', 'high', 'hope', 'stay', 'up', 'on', 'that', 'rise', 'stay', 'up', 'on', 'that', 'rise', 'and', 'never', 'come', 'down', 'oh', 'stay', 'up', 'on', 'that', 'rise', 'stay', 'up', 'on', 'that', 'rise', 'and', 'never', 'come', 'down', 'mama', 'said', 'do', \"n't\", 'give', 'up', 'it', \"'s\", 'a', 'little', 'complicated', 'all', 'tied', 'up', 'no', 'more', 'love', 'and', 'i', \"'d\", 'hate', 'to', 'see', 'you', 'waiting', 'they', 'say', 'it', \"'s\", 'all', 'been', 'done', 'but', 'they', 'have', \"n't\", 'seen', 'the', 'best', 'of', 'me-e-e-e', 'so', 'i', 'got', 'one', 'more', 'run', 'and', 'it', \"'s\", 'gon', 'na', 'be', 'a', 'sight', 'to', 'see-e-e-e', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'shooting', 'for', 'the', 'star', 'when', 'i', 'could', \"n't\", 'make', 'a', 'killing', 'did', \"n't\", 'have', 'a', 'dime', 'but', 'i', 'always', 'had', 'a', 'vision', 'always', 'had', 'high', 'high', 'hope', 'high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'did', \"n't\", 'know', 'how', 'but', 'i', 'always', 'had', 'a', 'feeling', 'i', 'wa', 'gon', 'na', 'be', 'that', 'one', 'in', 'a', 'million', 'always', 'had', 'high', 'high', 'hope', 'high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'shooting', 'for', 'the', 'star', 'when', 'i', 'could', \"n't\", 'make', 'a', 'killing', 'did', \"n't\", 'have', 'a', 'dime', 'but', 'i', 'always', 'had', 'a', 'vision', 'always', 'had', 'high', 'high', 'hope', 'had', 'to', 'have', 'high', 'high', 'hope', 'for', 'a', 'living', 'did', \"n't\", 'know', 'how', 'but', 'i', 'always', 'had', 'a', 'feeling', 'i', 'wa', 'gon', 'na', 'be', 'that', 'one', 'in', 'a', 'million', 'always', 'had', 'high', 'high', 'hope', 'high', 'high', 'hope']\n"
    }
   ],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "lemm_text = []\n",
    "\n",
    "for i in range(len(my_text)):\n",
    "    lemm_text.append(lem.lemmatize(my_text[i]))\n",
    "\n",
    "print(lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "107"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_count = len(set(lemm_text))\n",
    "unique_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "484"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lemm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}